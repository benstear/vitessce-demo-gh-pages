import _Math$log from "babel-runtime/core-js/math/log2";
import _Map from "babel-runtime/core-js/map";
import _Object$defineProperty from "babel-runtime/core-js/object/define-property";
import _Object$getOwnPropertyDescriptor from "babel-runtime/core-js/object/get-own-property-descriptor";
/**
 * @license
 * Copyright 2016 Google Inc.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
var __decorate = this && this.__decorate || function (decorators, target, key, desc) {
    var c = arguments.length,
        r = c < 3 ? target : desc === null ? desc = _Object$getOwnPropertyDescriptor(target, key) : desc,
        d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && _Object$defineProperty(target, key, r), r;
};
import { AnnotationPropertySerializer, annotationTypeHandlers, annotationTypes } from "../../annotation";
import { AnnotationGeometryData, AnnotationSource } from "../../annotation/backend";
import { AnnotationGeometryChunkSourceBackend } from "../../annotation/backend";
import { decodeGzip } from "../../async_computation/decode_gzip_request";
import { requestAsyncComputation } from "../../async_computation/request";
import { WithParameters } from "../../chunk_manager/backend";
import { GenericSharedDataSource } from "../../chunk_manager/generic_file_source";
import { WithSharedCredentialsProviderCounterpart } from "../../credentials_provider/shared_counterpart";
import { AnnotationSourceParameters, AnnotationSpatialIndexSourceParameters, DataEncoding, IndexedSegmentPropertySourceParameters, MeshSourceParameters, MultiscaleMeshSourceParameters, ShardingHashFunction, SkeletonSourceParameters, VolumeChunkEncoding, VolumeChunkSourceParameters } from "./base";
import { assignMeshFragmentData, assignMultiscaleMeshFragmentData, computeOctreeChildOffsets, decodeJsonManifestChunk, decodeTriangleVertexPositionsAndIndices, generateHigherOctreeLevel, MeshSource, MultiscaleMeshSource } from "../../mesh/backend";
import { IndexedSegmentPropertySourceBackend } from "../../segmentation_display_state/backend";
import { SkeletonSource } from "../../skeleton/backend";
import { decodeSkeletonChunk } from "../../skeleton/decode_precomputed_skeleton";
import { decodeCompressedSegmentationChunk } from "../../sliceview/backend_chunk_decoders/compressed_segmentation";
import { decodeCompressoChunk } from "../../sliceview/backend_chunk_decoders/compresso";
import { decodeJpegChunk } from "../../sliceview/backend_chunk_decoders/jpeg";
import { decodePngChunk } from "../../sliceview/backend_chunk_decoders/png";
import { decodeRawChunk } from "../../sliceview/backend_chunk_decoders/raw";
import { VolumeChunkSource } from "../../sliceview/volume/backend";
import { fetchSpecialHttpByteRange } from "../../util/byte_range_http_requests";
import { convertEndian32, Endianness } from "../../util/endian";
import { vec3 } from "../../util/geom";
import { murmurHash3_x86_128Hash64Bits } from "../../util/hash";
import { isNotFoundError, responseArrayBuffer, responseJson } from "../../util/http_request";
import { stableStringify } from "../../util/json";
import { getObjectId } from "../../util/object_id";
import { cancellableFetchSpecialOk } from "../../util/special_protocol_request";
import { Uint64 } from "../../util/uint64";
import { encodeZIndexCompressed, encodeZIndexCompressed3d, zorder3LessThan } from "../../util/zorder";
import { registerSharedObject } from "../../worker_rpc";
// Set to true to validate the multiscale index.
const DEBUG_MULTISCALE_INDEX = false;
const shardingHashFunctions = new _Map([[ShardingHashFunction.MURMURHASH3_X86_128, out => {
    murmurHash3_x86_128Hash64Bits(out, 0, out.low, out.high);
}], [ShardingHashFunction.IDENTITY, _out => {}]]);
function getMinishardIndexDataSource(chunkManager, credentialsProvider, parameters) {
    const url = parameters.url,
          sharding = parameters.sharding;

    if (sharding === undefined) return undefined;
    const source = GenericSharedDataSource.get(chunkManager, stableStringify({
        type: 'precomputed:shardedDataSource',
        url,
        sharding,
        credentialsProvider: getObjectId(credentialsProvider)
    }), {
        download: async function download(shardAndMinishard, cancellationToken) {
            const minishard = Uint64.lowMask(new Uint64(), sharding.minishardBits);
            Uint64.and(minishard, minishard, shardAndMinishard);
            const shard = Uint64.lowMask(new Uint64(), sharding.shardBits);
            const temp = new Uint64();
            Uint64.rshift(temp, shardAndMinishard, sharding.minishardBits);
            Uint64.and(shard, shard, temp);
            const shardUrl = `${url}/${shard.toString(16).padStart(Math.ceil(sharding.shardBits / 4), '0')}.shard`;
            // Retrive minishard index start/end offsets.
            const shardIndexSize = new Uint64(16);
            Uint64.lshift(shardIndexSize, shardIndexSize, sharding.minishardBits);
            // Multiply minishard by 16.
            const shardIndexStart = Uint64.lshift(new Uint64(), minishard, 4);
            const shardIndexEnd = Uint64.addUint32(new Uint64(), shardIndexStart, 16);
            let shardIndexResponse;
            try {
                shardIndexResponse = await fetchSpecialHttpByteRange(credentialsProvider, shardUrl, shardIndexStart, shardIndexEnd, cancellationToken);
            } catch (e) {
                if (isNotFoundError(e)) return { data: undefined, size: 0 };
                throw e;
            }
            if (shardIndexResponse.byteLength !== 16) {
                throw new Error(`Failed to retrieve minishard offset`);
            }
            const shardIndexDv = new DataView(shardIndexResponse);
            const minishardStartOffset = new Uint64(shardIndexDv.getUint32(0, /*littleEndian=*/true), shardIndexDv.getUint32(4, /*littleEndian=*/true));
            const minishardEndOffset = new Uint64(shardIndexDv.getUint32(8, /*littleEndian=*/true), shardIndexDv.getUint32(12, /*littleEndian=*/true));
            if (Uint64.equal(minishardStartOffset, minishardEndOffset)) {
                return { data: undefined, size: 0 };
            }
            // The start/end offsets in the shard index are relative to the end of the shard
            // index.
            Uint64.add(minishardStartOffset, minishardStartOffset, shardIndexSize);
            Uint64.add(minishardEndOffset, minishardEndOffset, shardIndexSize);
            let minishardIndexResponse = await fetchSpecialHttpByteRange(credentialsProvider, shardUrl, minishardStartOffset, minishardEndOffset, cancellationToken);
            if (sharding.minishardIndexEncoding === DataEncoding.GZIP) {
                minishardIndexResponse = (await requestAsyncComputation(decodeGzip, cancellationToken, [minishardIndexResponse], new Uint8Array(minishardIndexResponse))).buffer;
            }
            if (minishardIndexResponse.byteLength % 24 !== 0) {
                throw new Error(`Invalid minishard index length: ${minishardIndexResponse.byteLength}`);
            }
            const minishardIndex = new Uint32Array(minishardIndexResponse);
            convertEndian32(minishardIndex, Endianness.LITTLE);
            const minishardIndexSize = minishardIndex.byteLength / 24;
            let prevEntryKeyLow = 0,
                prevEntryKeyHigh = 0;
            // Offsets in the minishard index are relative to the end of the shard index.
            let prevStartLow = shardIndexSize.low,
                prevStartHigh = shardIndexSize.high;
            for (let i = 0; i < minishardIndexSize; ++i) {
                let entryKeyLow = prevEntryKeyLow + minishardIndex[i * 2];
                let entryKeyHigh = prevEntryKeyHigh + minishardIndex[i * 2 + 1];
                if (entryKeyLow >= 4294967296) {
                    entryKeyLow -= 4294967296;
                    entryKeyHigh += 1;
                }
                prevEntryKeyLow = minishardIndex[i * 2] = entryKeyLow;
                prevEntryKeyHigh = minishardIndex[i * 2 + 1] = entryKeyHigh;
                let startLow = prevStartLow + minishardIndex[(minishardIndexSize + i) * 2];
                let startHigh = prevStartHigh + minishardIndex[(minishardIndexSize + i) * 2 + 1];
                if (startLow >= 4294967296) {
                    startLow -= 4294967296;
                    startHigh += 1;
                }
                minishardIndex[(minishardIndexSize + i) * 2] = startLow;
                minishardIndex[(minishardIndexSize + i) * 2 + 1] = startHigh;
                const sizeLow = minishardIndex[(2 * minishardIndexSize + i) * 2];
                const sizeHigh = minishardIndex[(2 * minishardIndexSize + i) * 2 + 1];
                let endLow = startLow + sizeLow;
                let endHigh = startHigh + sizeHigh;
                if (endLow >= 4294967296) {
                    endLow -= 4294967296;
                    endHigh += 1;
                }
                prevStartLow = endLow;
                prevStartHigh = endHigh;
                minishardIndex[(2 * minishardIndexSize + i) * 2] = endLow;
                minishardIndex[(2 * minishardIndexSize + i) * 2 + 1] = endHigh;
            }
            return { data: { data: minishardIndex, shardUrl }, size: minishardIndex.byteLength };
        },
        encodeKey: key => key.toString(),
        sourceQueueLevel: 1
    });
    source.sharding = sharding;
    source.credentialsProvider = credentialsProvider;
    return source;
}
function findMinishardEntry(minishardIndex, key) {
    const minishardIndexData = minishardIndex.data;
    const minishardIndexSize = minishardIndexData.length / 6;
    const keyLow = key.low,
          keyHigh = key.high;
    for (let i = 0; i < minishardIndexSize; ++i) {
        if (minishardIndexData[i * 2] !== keyLow || minishardIndexData[i * 2 + 1] !== keyHigh) {
            continue;
        }
        const startOffset = new Uint64(minishardIndexData[(minishardIndexSize + i) * 2], minishardIndexData[(minishardIndexSize + i) * 2 + 1]);
        const endOffset = new Uint64(minishardIndexData[(2 * minishardIndexSize + i) * 2], minishardIndexData[(2 * minishardIndexSize + i) * 2 + 1]);
        return { startOffset, endOffset };
    }
    return undefined;
}
async function getShardedData(minishardIndexSource, chunk, key, cancellationToken) {
    const sharding = minishardIndexSource.sharding;

    const hashFunction = shardingHashFunctions.get(sharding.hash);
    const hashCode = Uint64.rshift(new Uint64(), key, sharding.preshiftBits);
    hashFunction(hashCode);
    const shardAndMinishard = Uint64.lowMask(new Uint64(), sharding.minishardBits + sharding.shardBits);
    Uint64.and(shardAndMinishard, shardAndMinishard, hashCode);
    const getPriority = () => ({ priorityTier: chunk.priorityTier, priority: chunk.priority });
    const minishardIndex = await minishardIndexSource.getData(shardAndMinishard, getPriority, cancellationToken);
    if (minishardIndex === undefined) return undefined;
    const minishardEntry = findMinishardEntry(minishardIndex, key);
    if (minishardEntry === undefined) return undefined;
    const startOffset = minishardEntry.startOffset,
          endOffset = minishardEntry.endOffset;

    let data = await fetchSpecialHttpByteRange(minishardIndexSource.credentialsProvider, minishardIndex.shardUrl, startOffset, endOffset, cancellationToken);
    if (minishardIndexSource.sharding.dataEncoding === DataEncoding.GZIP) {
        data = (await requestAsyncComputation(decodeGzip, cancellationToken, [data], new Uint8Array(data))).buffer;
    }
    return { data, shardInfo: { shardUrl: minishardIndex.shardUrl, offset: startOffset } };
}
function getOrNotFoundError(v) {
    if (v === undefined) throw new Error('not found');
    return v;
}
const chunkDecoders = new _Map();
chunkDecoders.set(VolumeChunkEncoding.RAW, decodeRawChunk);
chunkDecoders.set(VolumeChunkEncoding.JPEG, decodeJpegChunk);
chunkDecoders.set(VolumeChunkEncoding.COMPRESSED_SEGMENTATION, decodeCompressedSegmentationChunk);
chunkDecoders.set(VolumeChunkEncoding.COMPRESSO, decodeCompressoChunk);
chunkDecoders.set(VolumeChunkEncoding.PNG, decodePngChunk);
let PrecomputedVolumeChunkSource = class PrecomputedVolumeChunkSource extends WithParameters(WithSharedCredentialsProviderCounterpart()(VolumeChunkSource), VolumeChunkSourceParameters) {
    constructor() {
        super(...arguments);
        this.chunkDecoder = chunkDecoders.get(this.parameters.encoding);
        this.minishardIndexSource = getMinishardIndexDataSource(this.chunkManager, this.credentialsProvider, this.parameters);
        this.gridShape = (() => {
            const gridShape = new Uint32Array(3);
            var _spec = this.spec;
            const upperVoxelBound = _spec.upperVoxelBound,
                  chunkDataSize = _spec.chunkDataSize;

            for (let i = 0; i < 3; ++i) {
                gridShape[i] = Math.ceil(upperVoxelBound[i] / chunkDataSize[i]);
            }
            return gridShape;
        })();
    }
    async download(chunk, cancellationToken) {
        const parameters = this.parameters;
        const minishardIndexSource = this.minishardIndexSource;

        let response;
        if (minishardIndexSource === undefined) {
            let url;
            {
                // chunkPosition must not be captured, since it will be invalidated by the next call to
                // computeChunkBounds.
                let chunkPosition = this.computeChunkBounds(chunk);
                let chunkDataSize = chunk.chunkDataSize;
                url = `${parameters.url}/${chunkPosition[0]}-${chunkPosition[0] + chunkDataSize[0]}_` + `${chunkPosition[1]}-${chunkPosition[1] + chunkDataSize[1]}_` + `${chunkPosition[2]}-${chunkPosition[2] + chunkDataSize[2]}`;
            }
            response = await cancellableFetchSpecialOk(this.credentialsProvider, url, {}, responseArrayBuffer, cancellationToken);
        } else {
            this.computeChunkBounds(chunk);
            const gridShape = this.gridShape;
            const chunkGridPosition = chunk.chunkGridPosition;

            const xBits = Math.ceil(_Math$log(gridShape[0])),
                  yBits = Math.ceil(_Math$log(gridShape[1])),
                  zBits = Math.ceil(_Math$log(gridShape[2]));
            const chunkIndex = encodeZIndexCompressed3d(new Uint64(), xBits, yBits, zBits, chunkGridPosition[0], chunkGridPosition[1], chunkGridPosition[2]);
            response = getOrNotFoundError((await getShardedData(minishardIndexSource, chunk, chunkIndex, cancellationToken))).data;
        }
        await this.chunkDecoder(chunk, cancellationToken, response);
    }
};
PrecomputedVolumeChunkSource = __decorate([registerSharedObject()], PrecomputedVolumeChunkSource);
export { PrecomputedVolumeChunkSource };
export function decodeManifestChunk(chunk, response) {
    return decodeJsonManifestChunk(chunk, response, 'fragments');
}
export function decodeFragmentChunk(chunk, response) {
    let dv = new DataView(response);
    let numVertices = dv.getUint32(0, true);
    assignMeshFragmentData(chunk, decodeTriangleVertexPositionsAndIndices(response, Endianness.LITTLE, /*vertexByteOffset=*/4, numVertices));
}
let PrecomputedMeshSource = class PrecomputedMeshSource extends WithParameters(WithSharedCredentialsProviderCounterpart()(MeshSource), MeshSourceParameters) {
    async download(chunk, cancellationToken) {
        const parameters = this.parameters;

        const response = await cancellableFetchSpecialOk(this.credentialsProvider, `${parameters.url}/${chunk.objectId}:${parameters.lod}`, {}, responseJson, cancellationToken);
        decodeManifestChunk(chunk, response);
    }
    async downloadFragment(chunk, cancellationToken) {
        const parameters = this.parameters;

        const response = await cancellableFetchSpecialOk(this.credentialsProvider, `${parameters.url}/${chunk.fragmentId}`, {}, responseArrayBuffer, cancellationToken);
        decodeFragmentChunk(chunk, response);
    }
};
PrecomputedMeshSource = __decorate([registerSharedObject()], PrecomputedMeshSource);
export { PrecomputedMeshSource };
function decodeMultiscaleManifestChunk(chunk, response) {
    if (response.byteLength < 28 || response.byteLength % 4 !== 0) {
        throw new Error(`Invalid index file size: ${response.byteLength}`);
    }
    const dv = new DataView(response);
    let offset = 0;
    const chunkShape = vec3.fromValues(dv.getFloat32(offset, /*littleEndian=*/true), dv.getFloat32(offset + 4, /*littleEndian=*/true), dv.getFloat32(offset + 8, /*littleEndian=*/true));
    offset += 12;
    const gridOrigin = vec3.fromValues(dv.getFloat32(offset, /*littleEndian=*/true), dv.getFloat32(offset + 4, /*littleEndian=*/true), dv.getFloat32(offset + 8, /*littleEndian=*/true));
    offset += 12;
    const numStoredLods = dv.getUint32(offset, /*littleEndian=*/true);
    offset += 4;
    if (response.byteLength < offset + (4 + 4 + 4 * 3) * numStoredLods) {
        throw new Error(`Invalid index file size for ${numStoredLods} lods: ${response.byteLength}`);
    }
    const storedLodScales = new Float32Array(response, offset, numStoredLods);
    offset += 4 * numStoredLods;
    convertEndian32(storedLodScales, Endianness.LITTLE);
    const vertexOffsets = new Float32Array(response, offset, numStoredLods * 3);
    convertEndian32(vertexOffsets, Endianness.LITTLE);
    offset += 12 * numStoredLods;
    const numFragmentsPerLod = new Uint32Array(response, offset, numStoredLods);
    offset += 4 * numStoredLods;
    convertEndian32(numFragmentsPerLod, Endianness.LITTLE);
    const totalFragments = numFragmentsPerLod.reduce((a, b) => a + b);
    if (response.byteLength !== offset + 16 * totalFragments) {
        throw new Error(`Invalid index file size for ${numStoredLods} lods and ` + `${totalFragments} total fragments: ${response.byteLength}`);
    }
    const fragmentInfo = new Uint32Array(response, offset);
    convertEndian32(fragmentInfo, Endianness.LITTLE);
    const clipLowerBound = vec3.fromValues(Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY);
    const clipUpperBound = vec3.fromValues(Number.NEGATIVE_INFINITY, Number.NEGATIVE_INFINITY, Number.NEGATIVE_INFINITY);
    let numLods = Math.max(1, storedLodScales.length);
    // Compute `clipLowerBound` and `clipUpperBound` and `numLods`.  Note that `numLods` is >=
    // `storedLodScales.length`; it may contain additional levels since at the highest level the
    // octree must be a single node.
    {
        let fragmentBase = 0;
        for (let lodIndex = 0; lodIndex < numStoredLods; ++lodIndex) {
            const numFragments = numFragmentsPerLod[lodIndex];
            if (DEBUG_MULTISCALE_INDEX) {
                for (let i = 1; i < numFragments; ++i) {
                    let x0 = fragmentInfo[fragmentBase + numFragments * 0 + (i - 1)];
                    let y0 = fragmentInfo[fragmentBase + numFragments * 1 + (i - 1)];
                    let z0 = fragmentInfo[fragmentBase + numFragments * 2 + (i - 1)];
                    let x1 = fragmentInfo[fragmentBase + numFragments * 0 + i];
                    let y1 = fragmentInfo[fragmentBase + numFragments * 1 + i];
                    let z1 = fragmentInfo[fragmentBase + numFragments * 2 + i];
                    if (!zorder3LessThan(x0, y0, z0, x1, y1, z1)) {
                        console.log(`Fragment index violates zorder constraint: ` + `lod=${lodIndex}, ` + `chunk ${i - 1} = [${x0},${y0},${z0}], ` + `chunk ${i} = [${x1},${y1},${z1}]`);
                    }
                }
            }
            for (let i = 0; i < 3; ++i) {
                let upperBoundValue = Number.NEGATIVE_INFINITY;
                let lowerBoundValue = Number.POSITIVE_INFINITY;
                const base = fragmentBase + numFragments * i;
                for (let j = 0; j < numFragments; ++j) {
                    const v = fragmentInfo[base + j];
                    upperBoundValue = Math.max(upperBoundValue, v);
                    lowerBoundValue = Math.min(lowerBoundValue, v);
                }
                if (numFragments != 0) {
                    while (upperBoundValue >>> numLods - lodIndex - 1 != lowerBoundValue >>> numLods - lodIndex - 1) {
                        ++numLods;
                    }
                    if (lodIndex === 0) {
                        clipLowerBound[i] = Math.min(clipLowerBound[i], (1 << lodIndex) * lowerBoundValue);
                        clipUpperBound[i] = Math.max(clipUpperBound[i], (1 << lodIndex) * (upperBoundValue + 1));
                    }
                }
            }
            fragmentBase += numFragments * 4;
        }
    }
    // Compute upper bound on number of nodes that will be in the octree, so that we can allocate a
    // sufficiently large buffer without having to worry about resizing.
    let maxFragments = 0;
    {
        let prevNumFragments = 0;
        let prevLodIndex = 0;
        for (let lodIndex = 0; lodIndex < numStoredLods; ++lodIndex) {
            const numFragments = numFragmentsPerLod[lodIndex];
            maxFragments += prevNumFragments * (lodIndex - prevLodIndex);
            prevLodIndex = lodIndex;
            prevNumFragments = numFragments;
            maxFragments += numFragments;
        }
        maxFragments += (numLods - 1 - prevLodIndex) * prevNumFragments;
    }
    const octreeTemp = new Uint32Array(5 * maxFragments);
    const offsetsTemp = new Float64Array(maxFragments + 1);
    let octree;
    {
        let priorStart = 0;
        let baseRow = 0;
        let dataOffset = 0;
        let fragmentBase = 0;
        for (let lodIndex = 0; lodIndex < numStoredLods; ++lodIndex) {
            const numFragments = numFragmentsPerLod[lodIndex];
            // Copy in indices
            for (let j = 0; j < numFragments; ++j) {
                for (let i = 0; i < 3; ++i) {
                    octreeTemp[5 * (baseRow + j) + i] = fragmentInfo[fragmentBase + j + i * numFragments];
                }
                const dataSize = fragmentInfo[fragmentBase + j + 3 * numFragments];
                dataOffset += dataSize;
                offsetsTemp[baseRow + j + 1] = dataOffset;
                if (dataSize === 0) {
                    // Mark node as empty.
                    octreeTemp[5 * (baseRow + j) + 4] = 0x80000000;
                }
            }
            fragmentBase += 4 * numFragments;
            if (lodIndex !== 0) {
                // Connect with prior level
                computeOctreeChildOffsets(octreeTemp, priorStart, baseRow, baseRow + numFragments);
            }
            priorStart = baseRow;
            baseRow += numFragments;
            while (lodIndex + 1 < numLods && (lodIndex + 1 >= storedLodScales.length || storedLodScales[lodIndex + 1] === 0)) {
                const curEnd = generateHigherOctreeLevel(octreeTemp, priorStart, baseRow);
                offsetsTemp.fill(dataOffset, baseRow + 1, curEnd + 1);
                priorStart = baseRow;
                baseRow = curEnd;
                ++lodIndex;
            }
        }
        octree = octreeTemp.slice(0, 5 * baseRow);
        chunk.offsets = offsetsTemp.slice(0, baseRow + 1);
    }
    const source = chunk.source;
    const lodScaleMultiplier = source.parameters.metadata.lodScaleMultiplier;

    const lodScales = new Float32Array(numLods);
    lodScales.set(storedLodScales, 0);
    for (let i = 0; i < storedLodScales.length; ++i) {
        lodScales[i] *= lodScaleMultiplier;
    }
    chunk.manifest = {
        chunkShape,
        chunkGridSpatialOrigin: gridOrigin,
        clipLowerBound: vec3.add(clipLowerBound, gridOrigin, vec3.multiply(clipLowerBound, clipLowerBound, chunkShape)),
        clipUpperBound: vec3.add(clipUpperBound, gridOrigin, vec3.multiply(clipUpperBound, clipUpperBound, chunkShape)),
        octree,
        lodScales,
        vertexOffsets
    };
}
async function decodeMultiscaleFragmentChunk(chunk, response) {
    const lod = chunk.lod;

    const source = chunk.manifestChunk.source;
    const m = await import( /* webpackChunkName: "draco" */"../../mesh/draco");
    const rawMesh = await m.decodeDracoPartitioned(new Uint8Array(response), source.parameters.metadata.vertexQuantizationBits, lod !== 0);
    assignMultiscaleMeshFragmentData(chunk, rawMesh, source.format.vertexPositionFormat);
}
let PrecomputedMultiscaleMeshSource = class PrecomputedMultiscaleMeshSource extends WithParameters(WithSharedCredentialsProviderCounterpart()(MultiscaleMeshSource), MultiscaleMeshSourceParameters) {
    constructor() {
        super(...arguments);
        this.minishardIndexSource = getMinishardIndexDataSource(this.chunkManager, this.credentialsProvider, { url: this.parameters.url, sharding: this.parameters.metadata.sharding });
    }
    async download(chunk, cancellationToken) {
        const parameters = this.parameters,
              minishardIndexSource = this.minishardIndexSource;

        let data;
        if (minishardIndexSource === undefined) {
            data = await cancellableFetchSpecialOk(this.credentialsProvider, `${parameters.url}/${chunk.objectId}.index`, {}, responseArrayBuffer, cancellationToken);
        } else {
            var _getOrNotFoundError = getOrNotFoundError((await getShardedData(minishardIndexSource, chunk, chunk.objectId, cancellationToken)));

            data = _getOrNotFoundError.data;
            chunk.shardInfo = _getOrNotFoundError.shardInfo;
        }
        decodeMultiscaleManifestChunk(chunk, data);
    }
    async downloadFragment(chunk, cancellationToken) {
        const parameters = this.parameters;

        const manifestChunk = chunk.manifestChunk;
        const chunkIndex = chunk.chunkIndex;
        const shardInfo = manifestChunk.shardInfo,
              offsets = manifestChunk.offsets;

        const startOffset = offsets[chunkIndex];
        const endOffset = offsets[chunkIndex + 1];
        let requestUrl;
        let adjustedStartOffset, adjustedEndOffset;
        if (shardInfo !== undefined) {
            requestUrl = shardInfo.shardUrl;
            const fullDataSize = offsets[offsets.length - 1];
            let startLow = shardInfo.offset.low - fullDataSize + startOffset;
            let startHigh = shardInfo.offset.high;
            let endLow = startLow + endOffset - startOffset;
            let endHigh = startHigh;
            while (startLow < 0) {
                startLow += 4294967296;
                startHigh -= 1;
            }
            while (endLow < 0) {
                endLow += 4294967296;
                endHigh -= 1;
            }
            while (endLow > 4294967296) {
                endLow -= 4294967296;
                endHigh += 1;
            }
            adjustedStartOffset = new Uint64(startLow, startHigh);
            adjustedEndOffset = new Uint64(endLow, endHigh);
        } else {
            requestUrl = `${parameters.url}/${manifestChunk.objectId}`;
            adjustedStartOffset = startOffset;
            adjustedEndOffset = endOffset;
        }
        const response = await fetchSpecialHttpByteRange(this.credentialsProvider, requestUrl, adjustedStartOffset, adjustedEndOffset, cancellationToken);
        await decodeMultiscaleFragmentChunk(chunk, response);
    }
};
PrecomputedMultiscaleMeshSource = __decorate([registerSharedObject() //
], PrecomputedMultiscaleMeshSource);
export { PrecomputedMultiscaleMeshSource };
async function fetchByUint64(credentialsProvider, url, chunk, minishardIndexSource, id, cancellationToken) {
    if (minishardIndexSource === undefined) {
        try {
            return await cancellableFetchSpecialOk(credentialsProvider, `${url}/${id}`, {}, responseArrayBuffer, cancellationToken);
        } catch (e) {
            if (isNotFoundError(e)) return undefined;
            throw e;
        }
    }
    const result = await getShardedData(minishardIndexSource, chunk, id, cancellationToken);
    if (result === undefined) return undefined;
    return result.data;
}
let PrecomputedSkeletonSource = class PrecomputedSkeletonSource extends WithParameters(WithSharedCredentialsProviderCounterpart()(SkeletonSource), SkeletonSourceParameters) {
    constructor() {
        super(...arguments);
        this.minishardIndexSource = getMinishardIndexDataSource(this.chunkManager, this.credentialsProvider, { url: this.parameters.url, sharding: this.parameters.metadata.sharding });
    }
    async download(chunk, cancellationToken) {
        const parameters = this.parameters;

        const response = getOrNotFoundError((await fetchByUint64(this.credentialsProvider, parameters.url, chunk, this.minishardIndexSource, chunk.objectId, cancellationToken)));
        decodeSkeletonChunk(chunk, response, parameters.metadata.vertexAttributes);
    }
};
PrecomputedSkeletonSource = __decorate([registerSharedObject() //
], PrecomputedSkeletonSource);
export { PrecomputedSkeletonSource };
function parseAnnotations(buffer, parameters, propertySerializer) {
    const dv = new DataView(buffer);
    if (buffer.byteLength <= 8) throw new Error('Expected at least 8 bytes');
    const countLow = dv.getUint32(0, /*littleEndian=*/true);
    const countHigh = dv.getUint32(4, /*littleEndian=*/true);
    if (countHigh !== 0) throw new Error('Annotation count too high');
    const numBytes = propertySerializer.serializedBytes;
    const expectedBytes = 8 + (numBytes + 8) * countLow;
    if (buffer.byteLength !== expectedBytes) {
        throw new Error(`Expected ${expectedBytes} bytes, but received: ${buffer.byteLength} bytes`);
    }
    const idOffset = 8 + numBytes * countLow;
    const id = new Uint64();
    const ids = new Array(countLow);
    for (let i = 0; i < countLow; ++i) {
        id.low = dv.getUint32(idOffset + i * 8, /*littleEndian=*/true);
        id.high = dv.getUint32(idOffset + i * 8 + 4, /*littleEndian=*/true);
        ids[i] = id.toString();
    }
    const geometryData = new AnnotationGeometryData();
    const origData = new Uint8Array(buffer, 8, numBytes * countLow);
    let data;
    const propertyGroupBytes = propertySerializer.propertyGroupBytes;

    if (propertyGroupBytes.length > 1) {
        // Need to transpose the property data.
        data = new Uint8Array(origData.length);
        let origOffset = 0;
        let groupOffset = 0;
        for (let groupIndex = 0; groupIndex < propertyGroupBytes.length; ++groupIndex) {
            const groupBytesPerAnnotation = propertyGroupBytes[groupIndex];
            for (let annotationIndex = 0; annotationIndex < countLow; ++annotationIndex) {
                let origBase = origOffset + annotationIndex * numBytes;
                let newBase = groupOffset + annotationIndex * groupBytesPerAnnotation;
                for (let i = 0; i < groupBytesPerAnnotation; ++i) {
                    data[newBase + i] = origData[origBase + i];
                }
            }
            origOffset += groupBytesPerAnnotation;
            groupOffset += groupBytesPerAnnotation * countLow;
        }
    } else {
        data = origData;
    }
    geometryData.data = data;
    // FIXME: convert endian in order to support big endian platforms
    const typeToOffset = geometryData.typeToOffset = new Array(annotationTypes.length);
    typeToOffset.fill(0);
    typeToOffset[parameters.type] = 0;
    const typeToIds = geometryData.typeToIds = new Array(annotationTypes.length);
    const typeToIdMaps = geometryData.typeToIdMaps = new Array(annotationTypes.length);
    typeToIds.fill([]);
    typeToIds[parameters.type] = ids;
    typeToIdMaps.fill(new _Map());
    typeToIdMaps[parameters.type] = new _Map(ids.map((id, i) => [id, i]));
    return geometryData;
}
function parseSingleAnnotation(buffer, parameters, propertySerializer, id) {
    const handler = annotationTypeHandlers[parameters.type];
    const baseNumBytes = propertySerializer.serializedBytes;
    const numRelationships = parameters.relationships.length;
    const minNumBytes = baseNumBytes + 4 * numRelationships;
    if (buffer.byteLength < minNumBytes) {
        throw new Error(`Expected at least ${minNumBytes} bytes, but received: ${buffer.byteLength}`);
    }
    const dv = new DataView(buffer);
    const annotation = handler.deserialize(dv, 0, /*isLittleEndian=*/true, parameters.rank, id);
    propertySerializer.deserialize(dv, /*offset=*/0, /*annotationIndex=*/0, /*annotationCount=*/1, /*isLittleEndian=*/true, annotation.properties = new Array(parameters.properties.length));
    let offset = baseNumBytes;
    const relatedSegments = annotation.relatedSegments = [];
    relatedSegments.length = numRelationships;
    for (let i = 0; i < numRelationships; ++i) {
        const count = dv.getUint32(offset, /*littleEndian=*/true);
        if (buffer.byteLength < minNumBytes + count * 8) {
            throw new Error(`Expected at least ${minNumBytes} bytes, but received: ${buffer.byteLength}`);
        }
        offset += 4;
        const segments = relatedSegments[i] = [];
        for (let j = 0; j < count; ++j) {
            segments[j] = new Uint64(dv.getUint32(offset, /*littleEndian=*/true), dv.getUint32(offset + 4, /*littleEndian=*/true));
            offset += 8;
        }
    }
    if (offset !== buffer.byteLength) {
        throw new Error(`Expected ${offset} bytes, but received: ${buffer.byteLength}`);
    }
    return annotation;
}
let PrecomputedAnnotationSpatialIndexSourceBackend = class PrecomputedAnnotationSpatialIndexSourceBackend extends WithParameters(WithSharedCredentialsProviderCounterpart()(AnnotationGeometryChunkSourceBackend), AnnotationSpatialIndexSourceParameters) {
    constructor() {
        super(...arguments);
        this.minishardIndexSource = getMinishardIndexDataSource(this.chunkManager, this.credentialsProvider, this.parameters);
    }
    async download(chunk, cancellationToken) {
        const parameters = this.parameters;
        const minishardIndexSource = this.minishardIndexSource;
        const parent = this.parent;

        let response;
        const chunkGridPosition = chunk.chunkGridPosition;

        if (minishardIndexSource === undefined) {
            const url = `${parameters.url}/${chunkGridPosition.join('_')}`;
            try {
                response = await cancellableFetchSpecialOk(this.credentialsProvider, url, {}, responseArrayBuffer, cancellationToken);
            } catch (e) {
                if (!isNotFoundError(e)) throw e;
            }
        } else {
            const upperChunkBound = this.spec.upperChunkBound;
            const chunkGridPosition = chunk.chunkGridPosition;

            const chunkIndex = encodeZIndexCompressed(new Uint64(), chunkGridPosition, upperChunkBound);
            const result = await getShardedData(minishardIndexSource, chunk, chunkIndex, cancellationToken);
            if (result !== undefined) response = result.data;
        }
        if (response !== undefined) {
            chunk.data = parseAnnotations(response, parent.parameters, parent.annotationPropertySerializer);
        }
    }
};
PrecomputedAnnotationSpatialIndexSourceBackend = __decorate([registerSharedObject() //
], PrecomputedAnnotationSpatialIndexSourceBackend);
export { PrecomputedAnnotationSpatialIndexSourceBackend };
let PrecomputedAnnotationSourceBackend = class PrecomputedAnnotationSourceBackend extends WithParameters(WithSharedCredentialsProviderCounterpart()(AnnotationSource), AnnotationSourceParameters) {
    constructor() {
        super(...arguments);
        this.byIdMinishardIndexSource = getMinishardIndexDataSource(this.chunkManager, this.credentialsProvider, this.parameters.byId);
        this.relationshipIndexSource = this.parameters.relationships.map(x => getMinishardIndexDataSource(this.chunkManager, this.credentialsProvider, x));
        this.annotationPropertySerializer = new AnnotationPropertySerializer(this.parameters.rank, annotationTypeHandlers[this.parameters.type].serializedBytes(this.parameters.rank), this.parameters.properties);
    }
    async downloadSegmentFilteredGeometry(chunk, relationshipIndex, cancellationToken) {
        const parameters = this.parameters;

        const response = await fetchByUint64(this.credentialsProvider, parameters.relationships[relationshipIndex].url, chunk, this.relationshipIndexSource[relationshipIndex], chunk.objectId, cancellationToken);
        if (response !== undefined) {
            chunk.data = parseAnnotations(response, this.parameters, this.annotationPropertySerializer);
        }
    }
    async downloadMetadata(chunk, cancellationToken) {
        const parameters = this.parameters;

        const id = Uint64.parseString(chunk.key);
        const response = await fetchByUint64(this.credentialsProvider, parameters.byId.url, chunk, this.byIdMinishardIndexSource, id, cancellationToken);
        if (response === undefined) {
            chunk.annotation = null;
        } else {
            chunk.annotation = parseSingleAnnotation(response, this.parameters, this.annotationPropertySerializer, chunk.key);
        }
    }
};
PrecomputedAnnotationSourceBackend = __decorate([registerSharedObject() //
], PrecomputedAnnotationSourceBackend);
export { PrecomputedAnnotationSourceBackend };
let PrecomputedIndexedSegmentPropertySourceBackend = class PrecomputedIndexedSegmentPropertySourceBackend extends WithParameters(WithSharedCredentialsProviderCounterpart()(IndexedSegmentPropertySourceBackend), IndexedSegmentPropertySourceParameters) {
    constructor() {
        super(...arguments);
        this.minishardIndexSource = getMinishardIndexDataSource(this.chunkManager, this.credentialsProvider, this.parameters);
    }
};
PrecomputedIndexedSegmentPropertySourceBackend = __decorate([registerSharedObject()], PrecomputedIndexedSegmentPropertySourceBackend);
export { PrecomputedIndexedSegmentPropertySourceBackend };
//# sourceMappingURL=backend.js.map